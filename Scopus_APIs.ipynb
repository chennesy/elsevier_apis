{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d902ff52-73ac-4743-84cc-df9e9df1f638",
   "metadata": {},
   "source": [
    "## Using Elsevier APIs\n",
    "\n",
    "This notebook provides code that you can adapt to use with the [Scopus Search API](https://dev.elsevier.com/documentation/ScopusSearchAPI.wadl) and the [Abstract Retrieval Search API](https://dev.elsevier.com/documentation/AbstractRetrievalAPI.wadl). It includes:\n",
    "1. Setting up access to Elsevier APIs.\n",
    "2. Constructing a search template for sending different kinds of searches to the Scopus Search API (e.g., keyword, author name, ISSN).\n",
    "3. Using an ISSN search with date limiters to send a larger search to the Scopus Search API, and paging through the results. \n",
    "4. Exploring JSON data that is returned from the API. \n",
    "5. Sending DOIs to the Abstract Search API to retrieve more robust metadata.\n",
    "\n",
    "To begin, we need to import a few Python libraries to work with the APIs and the returned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0239e-f7e9-45ba-8cdd-3c7ff1002910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # allows us to work with tabular data\n",
    "import requests # to send the API requests to Elsevier\n",
    "import json # to read the JSON data that is returned by the APIs\n",
    "import pickle # pickle files are a good way to save data for reuse in Python\n",
    "from datetime import datetime # we'll use datetime to interpret the API response for when our API limit resets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7e7fdd-00ac-4c9b-9515-072a86257f55",
   "metadata": {},
   "source": [
    "### Elsevier APIs\n",
    "To use these APIs you'll need to register for an API key via the [Elsevier Developer site](https://dev.elsevier.com/). A note on access from the Elsevier site:\n",
    "\n",
    ">Anyone can request an API Key to use Elsevier APIs. Access at no charge is available to researchers in academic, public-sector and not-for-profit institutions. Free access is only available for non-commercial use and provided Elsevier's policies for using APIs and the data are honoured.\n",
    "\n",
    ">Full API access is only granted to researchers affiliated to organisations that have subscriptions to the corresponding Elsevier product.\n",
    "\n",
    "If you are affiliated with an institution with Elsevier access, make sure you send your API request from an on-campus IP address or use a VPN. Elsevier doesn't offer a way to sign in with campus credentials, so you'll need to run this from within an approved IP range for access to non-open-access content.\n",
    "\n",
    "Once you have an API key, you can save it to a variable below. Make sure you don't save your API key anywhere publicly (such as on GitHub). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b0c9f-de8f-481c-8c5a-915b015f62f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7138d55-94f7-4b97-9992-12669d75ded9",
   "metadata": {},
   "source": [
    "### Scopus Search API: Constructing a search query\n",
    "To add search parameters to our API search we'll start with a few fields. Ignore any of the variables that you don't want to use by just leaving the value unchanged - ```0``` or an empty string (```''```). To use any of the fields in your search, add a value.\n",
    "\n",
    "- See [Elsevier's documentation](https://dev.elsevier.com/sc_search_tips.html) to find field names to add more search paramters and to format your searches below.\n",
    "- You can also [test Scopus queries](https://dev.elsevier.com/scopus.html#!/Scopus_Search/ScopusSearch) using their interactive API. This is a great way to see how search string parameters are added to the URLs sent to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631369eb-603d-4799-92d5-5f9edeb36833",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''search parameters: add values to the dictionary key:value pairs below\n",
    "leave any fields that you don't want to use as either 0 or '''\n",
    "\n",
    "search_string_parameters = {\n",
    "    'ISSN' : '', # Limit results to results from a journal ISSN (add as a string). Leave = '' if no value.\n",
    "    'AUTHOR-NAME' : '', # Search the author name field. lastname, firstname. e.g., Noble, Safiya\n",
    "    'KEY' : '', # Add a keyword to search in the text of the article\n",
    "    'PUBLISHER' : '', # Add a publisher name. e.g., Springer\n",
    "    'EXACTSRCTITLE' : 'libraries', # Add keywords that appear in the journal, book, or conference title. e.g., Informatics\n",
    "    'AFFIL' : '', # add keywords that appear in the author's institutional affiliation. e.g., to find the University of Minnesota, search for University and Minnesota\n",
    "    'TITLE' : '', # Add keywords that appear in the article or chapter title. Can use AND, OR, and AND NOT. e.g. cat AND dog \n",
    "    'OPENACCESS' : '1', # Add 1 to limit your results to open access articles or 0 for articles that are not open access\n",
    "    'start_year' : 2015, # Limit your search to items published after this year. Leave = 0 if no value. YYYY , e.g., 1995\n",
    "    'end_year' : 0 # Limit your search to items published before this year. Leave = 0 if no value. YYYY, e.g., 2020\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63889d37-9ed0-4bc0-9839-2a45e34bce45",
   "metadata": {},
   "source": [
    "The cell below constructs an encoded search string based on the values entered above. It checks if each of the search string parameter keys (e.g., ISSN) has a value assigned to it. If there's a value it adds it to the search_string variable using the proper syntax. If none of the keys in search_string_parameters have values search_string will be empty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bbf01c-7e5a-4776-bba6-45721a925bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_builder(search_string_parameters):\n",
    "    ''' Concatenates a search string query formatted for the Scopus Search API.\n",
    "    - search_string_parameters expects a python dictionary with keys aligned to API search fields.\n",
    "    '''\n",
    "    search_string = ''\n",
    "\n",
    "    for k,v in search_string_parameters.items():\n",
    "        if k == 'start_year' and v:\n",
    "            if search_string != '':\n",
    "                search_string += f' AND '\n",
    "            search_string += f'PUBYEAR > {v}'\n",
    "        elif k == 'end_year' and v:\n",
    "            if search_string != '':\n",
    "                search_string += f' AND '\n",
    "            search_string += f'PUBYEAR < {v}'\n",
    "        elif v:\n",
    "            if search_string != '':\n",
    "                search_string += f' AND '\n",
    "            search_string += f'{k}({v})'\n",
    "\n",
    "    return search_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac5804-27da-481f-b995-9350827f5b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string = search_builder(search_string_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87164eb-cf16-4292-964d-63e5014b2d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1650d750-e5b1-4aaf-be3f-bb2ba4b590a0",
   "metadata": {},
   "source": [
    "Now we'll create two functions that we can use to interact with the Scopus Search API. The first - ```create_url``` - uses the ```search_string``` and ```api_key``` variables we defined above to format a URL API call. The second - ```connect_to_endpoint``` - sends the request to Elsevier, and introduces a ```next_``` parameter that we'll use to page through results when there are more than 25 results for our search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b099998c-5f30-4cfe-a83e-996361b83521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(search_string):\n",
    "    '''Accepts a formatted search string that will be added to the Scopus Search API URL. \n",
    "    Requires a global api_key variable.\n",
    "    Formats and returns a URL to send to the Scopus Search API.'''\n",
    "    \n",
    "    query = f'{search_string}'\n",
    "    url_template = 'https://api.elsevier.com/content/search/scopus?query={query}&apiKey={api_key}'\n",
    "    full_url = url_template.format(query=query, api_key=api_key)\n",
    "    return full_url\n",
    "\n",
    "def connect_to_endpoint(full_url, params={'cursor': '*'}, next_ = '*'):\n",
    "    '''Accepts API URL with ISSN, default parameters, and next page cursor;\n",
    "    Sends request to Scopus API and collects JSON results for each call;\n",
    "    Returns r.json() for the ['search-results'] key.'''\n",
    "    \n",
    "    params['cursor'] = next_\n",
    "    r = requests.get(full_url, params=params)\n",
    "    r.raise_for_status()\n",
    "    return r.json()['search-results'], r.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b66724-89f1-4ac9-82d3-898c5c4ebef3",
   "metadata": {},
   "source": [
    "#### Example Search\n",
    "Once you've assigned your API key and at least one search field above, and run all of the code preceding, you can send a search to the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97acf646-9792-46c1-875e-476d88dd8b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_url = create_url(search_string)\n",
    "r_json, r_headers = connect_to_endpoint(full_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dfbb9f-cf5d-49d9-abf7-fa20dcd2d28c",
   "metadata": {},
   "source": [
    "Our function returns the JSON response from the API call (```r_json```) along with the headers from the response (```r_headers```). The latter has some useful information about our API key limits. We're probably most interested in the ```X-RateLimit-Limit``` (how many calls we can make per week to the API), the ```X-RateLimit-Remaining``` (how many we have left in the week), and the ```X-RateLimit-Reset``` (when the week counter resets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e9638-03cd-4048-a45a-c69901b6447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Limit:', r_headers['X-RateLimit-Limit'], \n",
    "      '\\nRemaining:', r_headers['X-RateLimit-Remaining'], \n",
    "      '\\nResets on:', datetime.fromtimestamp(int(r_headers['X-RateLimit-Reset'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690fb72a-4096-4d11-a45c-ac1b0586e041",
   "metadata": {},
   "source": [
    "Since we didn't have either of the functions print any outputs, the call should be successful as long as we don't see any errors pop up. We can check by looking at the r_json object that we collected. The keys of the dictionary will show us what kind of data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9a671-fabc-457a-9c4a-0b228f144045",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499b3a8-1718-4b8d-8875-0408d8aebfa0",
   "metadata": {},
   "source": [
    "Let's first see how many search results there were, and how many of those were returned by our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba9150a-88a6-45a7-a1e2-075c4ef8dc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total results:\", r_json['opensearch:totalResults'], \n",
    "      \"\\nResults collected:\", r_json['opensearch:itemsPerPage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e7147-7d2e-441e-809d-0f588c45b9c1",
   "metadata": {},
   "source": [
    "It looks like we're only getting 25 results per page. We will page through more results in the next section but let's look at some of the data we got back from the query first. We can find that in the ```entry``` key. Since we know there are 25 results, let's just look at the first one to begin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2aed0-9edd-47e5-a54d-3a97a78a6799",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json['entry'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c90e2-7ce6-4edd-9357-98473e3714c0",
   "metadata": {},
   "source": [
    "To get a sense of the fields that we have access to we can also just look at the keys related to each entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a4d43-4048-47fa-8691-5d6c57edaeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json['entry'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df8e15-94ba-49d5-944a-1eeaac424070",
   "metadata": {},
   "source": [
    "And we can print specific fields by referencing those keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3043cc6-00f6-436e-b946-0b48a1d38bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Title:', r_json['entry'][0]['dc:title'], \n",
    "      '\\nCreator:', r_json['entry'][0]['dc:creator'], \n",
    "      '\\nPublication:', r_json['entry'][0]['prism:publicationName'],\n",
    "      '\\nDate:', r_json['entry'][0]['prism:coverDate'],\n",
    "      '\\nISSN:', r_json['entry'][0]['prism:issn'], \n",
    "      '\\nDOI:', r_json['entry'][0]['prism:doi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695cc98-ff0c-4437-bf60-b4571fb017a4",
   "metadata": {},
   "source": [
    "A better way to view and work with this data is to add it to a dataframe so we can see all of the articles as rows, with columns for each field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec386ff-48c8-4383-9f3e-9fe55b703689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(r_json['entry'])\n",
    "\n",
    "# check the first three rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4264d-c292-4004-a952-8d44b4f55c11",
   "metadata": {},
   "source": [
    "There are some columns that are left out of the display above (see the ellipsis in the center of the dataframe). Let's take a look at the full column list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c89eba-1b3f-4392-bfb0-6c900e6ef512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e68ac-587d-4f65-9dfb-91859752859d",
   "metadata": {},
   "source": [
    "We can view a subset of the dataframe to make it easier to scan columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e87c45-3df5-41ba-895e-9f91ac33cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['dc:title', 'prism:publicationName','prism:coverDate', 'dc:creator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7802dd-9f1f-4225-858c-6e39ab5b603d",
   "metadata": {},
   "source": [
    "### Query by journal ISSN\n",
    "Here's an example where we page through more than 25 search results, by asking for all of the articles from a specific ISSN within a date range. Let's re-assign our search parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ca526a-8e31-4820-9c33-4bad12931d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string_parameters = {\n",
    "    'ISSN' : '23301643', # the ISSN for Journal of the Association for Information Science and Technology (JASIST)\n",
    "    'AUTHOR-NAME' : '', \n",
    "    'KEY' : '', \n",
    "    'PUBLISHER' : '', \n",
    "    'EXACTSRCTITLE' : '', \n",
    "    'TITLE' : '', \n",
    "    'start_year' : 2013, \n",
    "    'end_year' : 2018 \n",
    "}\n",
    "search_string = search_builder(search_string_parameters)\n",
    "print(search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e80f1d-d985-4621-87d9-c804dbafc45f",
   "metadata": {},
   "source": [
    "This time we want to send in our API call repeatedly, so every page of search results (25 at a time). We can use a while statement to continue to call the API and collect results until the ```r_json['cursor'][@next]``` value is equal to the ```r_json['cursor'][@current]``` value (meaning there are no more new results reflected in the @next token).\n",
    "\n",
    "Before we send each request, we also want to make sure we're following [Elsevier's throttling rates](https://dev.elsevier.com/api_key_settings.html) so that we're not running into our weekly limit or sending in more calls per second than are allowed. The default settings for the Scopus Search API are 20,000 results per week, and 9 requests per second. We can import and use the time.sleep() method to pause our requests by 0.12 seconds each iteration of the while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3434c4-eef4-45d6-9ba5-2d7c7749ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e19efe-7486-4bbf-a895-f5d05079c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create default values for variable to track during while statement\n",
    "next_ = '*'\n",
    "flag = True\n",
    "\n",
    "# when there are no more results we'll set the flag to false, stopping the while statement\n",
    "while flag:\n",
    "    # pause for .12 seconds\n",
    "    time.sleep(0.12)\n",
    "    \n",
    "    #create url and send API call\n",
    "    full_url = create_url(search_string)\n",
    "    r_json, r_headers = connect_to_endpoint(full_url, next_ = next_)\n",
    "\n",
    "    # track number of results\n",
    "    total_results = int(r_json['opensearch:totalResults'])\n",
    "    \n",
    "    # if on first page of results save to new dataframe\n",
    "    if r_json['cursor']['@current'] == '*':\n",
    "        print('Collecting', total_results, 'results.')\n",
    "        print('Limit:', r_headers['X-RateLimit-Limit'], \n",
    "          '\\nRemaining:', r_headers['X-RateLimit-Remaining'], \n",
    "          '\\nResets on:', datetime.fromtimestamp(int(r_headers['X-RateLimit-Reset'])))\n",
    "        df = pd.DataFrame(r_json['entry'])\n",
    "        \n",
    "        # if there are more results available than are remaining in your weekly limit, stop the while loop\n",
    "        if total_results > int(r_headers['X-RateLimit-Remaining']):\n",
    "            print(\"\\n** Too many results to collect this week - stopping loop. **\")\n",
    "            break \n",
    "    \n",
    "    # if we're on the last page of results, change flag to False and end While statement\n",
    "    elif r_json['cursor']['@next'] == r_json['cursor']['@current']:\n",
    "        print('Loop done. Collected', len(df), 'rows.')\n",
    "        flag = False\n",
    "    \n",
    "    # otherwise add result to existing df and continue\n",
    "    else:\n",
    "        df_add = pd.DataFrame(r_json['entry'])\n",
    "        df = pd.concat([df, df_add])\n",
    "    \n",
    "    # update the next_ variable for the next iteration through the while statement\n",
    "    next_ = r_json['cursor']['@next']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1ea0d-59a5-4c57-ae22-f0da52f37136",
   "metadata": {},
   "source": [
    "We can take a look at the first few rows of the dataframe to make sure things look ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c668f-4d6b-48a6-b998-8a3d8dd4a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b67cdb-fc43-4f18-ba82-d61397420d5d",
   "metadata": {},
   "source": [
    "We can also call a subset of the dataframe columns to look at interesting metadata, and sort the results by the articles that are the most highly cited (using the ```citedby-count``` field)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d079c0-5f2f-492b-8a11-2f2b9bab6d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['dc:title', 'prism:coverDate', 'dc:creator', 'citedby-count']].sort_values(by='citedby-count', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb65c5-302c-4147-a2fd-c66d16254911",
   "metadata": {},
   "source": [
    "### Save the results\n",
    "After collecting data it's a good idea to save it to a pickle file which can be read into Python later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ef02d-58f3-47c5-908c-5cb1eee021d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api_results.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb754fc6-ed7e-41e2-84dc-ec8058ca7808",
   "metadata": {},
   "source": [
    "And here's how you can reassign the pickle file to a python variable to use in a different notebook or in a future session (after you stop this kernel). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4ab3c-979c-421e-b2c4-603509f1f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('api_results.pickle', 'rb') as handle:\n",
    "    articles_df = pickle.load(handle)\n",
    "\n",
    "# check to make sure the pickle file is the exact same as the original dataframe\n",
    "print('The dataframes are equal:', df.equals(articles_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807da16-4c8a-49a7-96d5-792230a18710",
   "metadata": {},
   "source": [
    "### Abstract Retrieval API: DOI search\n",
    "\n",
    "Let's modify our create_url and connect_to_endpoint functions to work specifically with DOIs in the Abstract Retrieval API.\n",
    "\n",
    "Since the only metadata we need to send to the Abstract Retrieval API is an article DOI, we'll change the create_url function to work with DOIs. We'll also modify connect_to_endpoint to add a header that asks for the data back in JSON format, and we'll remove the need to page through results (each DOI query should only find one match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d844da-7b39-4d42-9cec-280f54a925f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(doi):\n",
    "    \"\"\"Accepts a DOI as a string that will be added to the Abstract Retrieval API URL. \n",
    "    Requires a global api_key variable.\n",
    "    Formats and returns a URL to send to the Abstract Retrieval API.\n",
    "    \"\"\"\n",
    "    doi = f'{doi}'\n",
    "    url_template = 'https://api.elsevier.com/content/abstract/doi/{doi}?&apiKey={api_key}'\n",
    "    full_url = url_template.format(doi=doi, api_key=api_key)\n",
    "    return full_url\n",
    "\n",
    "def connect_to_endpoint(full_url):\n",
    "    '''Input full_url from create_url function;\n",
    "    Send request to Scopus Abstract Retrieval API\n",
    "    Returns r.json response;'''\n",
    "    \n",
    "    r = requests.get(full_url, headers =  {'Accept': 'application/json'})\n",
    "    r.raise_for_status()\n",
    "    return r.json(), r.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ab271-5b8c-4109-a850-b5261e00fb27",
   "metadata": {},
   "source": [
    "You can load your own list of DOIs to work with here. This example below uses a random sample of 25 DOIs from LIS journals over the last 20 years. First we'll load the DOIs from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ff068-24a9-47e3-8b5a-7618698567bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample of 25 DOIs from LIS journals\n",
    "dois = pd.read_csv('doi_sample.csv')\n",
    "dois.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6488657f-8c5d-492e-9191-739284db4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dois.loc[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc19974d-f321-417a-9301-3a247ed224bf",
   "metadata": {},
   "source": [
    "We can test the code using a single DOI from the list. First we'll build the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d1335-04e7-46a0-9a03-fb7de7352aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_url = create_url(dois.loc[0][0])\n",
    "print(full_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6ed3c7-17ab-44c9-9550-9c4564064a76",
   "metadata": {},
   "source": [
    "Then we can make the API request. You might notice that your API rate limit is different for the Abstract Retrieval API, and that the number of requests you can make for this API doesn't count against the requests you made for the Scopus Search API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec777e83-e076-4b1e-b7ca-ad74db7127ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json, r_headers = connect_to_endpoint(full_url)\n",
    "print('Limit:', r_headers['X-RateLimit-Limit'], \n",
    "      '\\nRemaining:', r_headers['X-RateLimit-Remaining'], \n",
    "      '\\nResets on:', datetime.fromtimestamp(int(r_headers['X-RateLimit-Reset'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c46d40-d44f-4fd1-a803-74fd9819c59f",
   "metadata": {},
   "source": [
    "Let's take a closer look at the r_json object by listing the dictionary keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a88756-ba06-4170-a6e2-bf78fcd16616",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8311fe-52e3-4e1c-b761-a27a4c070698",
   "metadata": {},
   "source": [
    "We can look at the record in a dataframe, though as we look at the results many of the cells contain chains of other key:value pairs that are a little difficult to read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a1ade-c72c-4860-9933-9db7d874fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json = r_json['abstracts-retrieval-response']\n",
    "abstract_df = pd.json_normalize(r_json)\n",
    "abstract_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fbf621-54bd-4eda-975a-4f85fe5a1a7d",
   "metadata": {},
   "source": [
    "Let's print out the cell values from each column to get a better sense of all of the data available in the JSON response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2964765-9ee2-4121-b5a5-d6b68469d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in abstract_df.columns:\n",
    "    print(col, '\\n', abstract_df.loc[0, col], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb6c98-f259-4890-b90f-b46547c847a4",
   "metadata": {},
   "source": [
    "We can save a subset of the columns to a new dataframe to make the data a little easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0c07c7-77b6-41b3-b5a1-3411fec3776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_df_min = abstract_df[['affiliation',\n",
    "       'item.bibrecord.head.source.publicationdate.year',\n",
    "       'item.bibrecord.tail.bibliography.@refcount',\n",
    "       'coredata.prism:issueIdentifier', \n",
    "       'coredata.dc:description', 'coredata.prism:coverDate',\n",
    "       'coredata.prism:aggregationType', 'coredata.prism:url',\n",
    "       'coredata.subtypeDescription',\n",
    "       'coredata.prism:publicationName', \n",
    "       'coredata.citedby-count', 'coredata.prism:volume', \n",
    "       'coredata.prism:pageRange', 'coredata.dc:title',\n",
    "       'coredata.openaccessFlag', 'coredata.prism:doi', 'coredata.prism:issn',\n",
    "       'authors.author']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe67341-1917-4487-b86f-11cc73c4ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_df_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1719fc-7e0f-47de-abe3-c599c8aa15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the abstract is available in a few different places\n",
    "print(r_json['item']['bibrecord']['head']['abstracts'])\n",
    "print(r_json['coredata']['dc:description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1528775-379c-4222-9d7e-2de26e9fb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_json['authors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add19a73-42be-4f8e-a6cb-72ab92d9582e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
